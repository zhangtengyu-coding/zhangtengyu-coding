<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>用自定义损失函数实现选择启用不同子网络 - 张胜东的博客</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="张胜东" /><meta name="description" content="背景 最近发现有一道题，还挺有意思的。题目大意是，每条训练样本是一个文章对，labelA标签标识这两篇文章相似，labelB标签标识这两篇文章" /><meta name="keywords" content="张胜东, 博客, 编程" />


<meta name="baidu-site-verification" content="qWR9jJPJ9e" />
<meta name="google-site-verification" content="s9FkJZw4X2alyC8-nsdZgiPHBwX6uqr1QVNxRaGfDKY" />


<meta name="generator" content="Hugo 0.68.3 with theme even" />


<link rel="canonical" href="https://www.zhangshengdong.com/post/custom_loss_to_switch_network/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<link href="/sass/main.min.2e81bbed97b8b282c1aeb57488cc71c8d8c8ec559f3931531bd396bf31e0d4dd.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:title" content="用自定义损失函数实现选择启用不同子网络" />
<meta property="og:description" content="背景 最近发现有一道题，还挺有意思的。题目大意是，每条训练样本是一个文章对，labelA标签标识这两篇文章相似，labelB标签标识这两篇文章" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://www.zhangshengdong.com/post/custom_loss_to_switch_network/" />
<meta property="article:published_time" content="2021-03-31T01:14:58+08:00" />
<meta property="article:modified_time" content="2021-09-09T04:13:14+08:00" />
<meta itemprop="name" content="用自定义损失函数实现选择启用不同子网络">
<meta itemprop="description" content="背景 最近发现有一道题，还挺有意思的。题目大意是，每条训练样本是一个文章对，labelA标签标识这两篇文章相似，labelB标签标识这两篇文章">
<meta itemprop="datePublished" content="2021-03-31T01:14:58&#43;08:00" />
<meta itemprop="dateModified" content="2021-09-09T04:13:14&#43;08:00" />
<meta itemprop="wordCount" content="6074">



<meta itemprop="keywords" content="深度学习,自定义,损失函数,子网络,keras," /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="用自定义损失函数实现选择启用不同子网络"/>
<meta name="twitter:description" content="背景 最近发现有一道题，还挺有意思的。题目大意是，每条训练样本是一个文章对，labelA标签标识这两篇文章相似，labelB标签标识这两篇文章"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">张胜东的博客</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/about/">
        <li class="mobile-menu-item">About</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">张胜东的博客</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/about/">About</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">用自定义损失函数实现选择启用不同子网络</h1>

      <div class="post-meta">
        <span class="post-time"> 2021-03-31 </span>
        
          <span class="more-meta"> 约 6074 字 </span>
          <span class="more-meta"> 预计阅读 13 分钟 </span>
        <span id="busuanzi_container_page_pv" class="more-meta"> <span id="busuanzi_value_page_pv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> 次阅读 </span>
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content always-active">
    <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#背景">背景</a></li>
        <li><a href="#自定义loss函数">自定义loss函数</a></li>
        <li><a href="#模型定义">模型定义</a></li>
        <li><a href="#tip">TIP：</a></li>
        <li><a href="#附录">附录</a>
          <ul>
            <li><a href="#全部源码">全部源码</a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <h2 id="背景">背景</h2>
<p>最近发现有一道题，还挺有意思的。题目大意是，每条训练样本是一个文章对，labelA标签标识这两篇文章相似，labelB标签标识这两篇文章属于同一事件(即紧相似)，但这个文章对不会同时拥有两个标签，即要么有A标签，要么有B标签，且A、B标签的文章对不重合。</p>
<p>面对这道题，一般的思路是建立两个模型。但因为标签A、B其实是有相似程度上的联系的，单独训练两个模型就失去了标签的相关性，感觉比较亏。</p>
<p>但如果要训练多任务的单模型，也比较麻烦。因为一个样本不能同时拥有这两个标签，而且比如不属于同一事件，没办法推出是否相似，即无法构造出缺失的标签。</p>
<p>所以想到，利用一个类似mask的特殊标签取值，来控制启用哪个子网络去训练。具体实现措施准备把另一个子网络的loss置0，以此不让其训练。</p>
<h2 id="自定义loss函数">自定义loss函数</h2>
<p>由于标签值是0、1，所以将 -1 设置为mask值。若y_true中为 -1 ，则将对应位置的y_true和y_pred替换为0，以此使其对应样本的loss为0。</p>
<p>最后，由于标签是0、1，所以采用 binary_crossentropy 作为损失函数：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">transform_y</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="n">mask_value</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">mask_y_true</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">not_equal</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">mask_value</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span>
<span class="c1">#     print(f&#34;mask_y_true:{mask_y_true}&#34;)</span>
<span class="c1">#     y_true_ = tf.cond(tf.equal(y_true, mask_value), lambda: 0, lambda: y_true)</span>
    <span class="n">y_true_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">mask_y_true</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">y_pred_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">mask_y_true</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="c1">#     print(f&#34;y_true_:{y_true_}, y_pred_:{y_pred_}&#34;)</span>
    
    <span class="k">return</span> <span class="n">y_true_</span><span class="p">,</span> <span class="n">y_pred_</span>


<span class="k">def</span> <span class="nf">my_binary_crossentropy</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
<span class="c1">#     print(f&#34;y_true:{y_true}, y_pred:{y_pred}&#34;)</span>
    
    <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="n">transform_y</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="c1">#     print(f&#34;y_true_:{y_true}, y_pred_:{y_pred}&#34;)</span>

    <span class="n">loss</span> <span class="o">=</span> <span class="n">binary_crossentropy</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="c1">#     print(f&#34;loss:{loss}&#34;)</span>
    <span class="k">return</span> <span class="n">loss</span>


<span class="k">def</span> <span class="nf">tarnsform_metrics</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="n">y_true_</span><span class="p">,</span> <span class="n">y_pred_</span> <span class="o">=</span> <span class="n">y_true</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">y_true_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">y_true_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="k">if</span> <span class="n">y_true_</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
                <span class="n">y_true_</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="n">y_pred_</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">if</span> <span class="n">y_pred_</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">:</span>
                <span class="n">y_pred_</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">y_pred_</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">return</span> <span class="n">y_true_</span><span class="p">,</span> <span class="n">y_pred_</span>


<span class="k">def</span> <span class="nf">my_binary_accuracy</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
<span class="c1">#     print(&#34;my_binary_accuracy&#34;)</span>
<span class="c1">#     print(f&#34;y_true:{y_true}, y_pred:{y_pred}&#34;)</span>
    
    <span class="n">y_true_</span><span class="p">,</span> <span class="n">y_pred_</span> <span class="o">=</span> <span class="n">tarnsform_metrics</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="c1">#     print(f&#34;y_true_:{y_true_}, y_pred_:{y_pred_}&#34;)</span>

    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">binary_accuracy</span><span class="p">(</span><span class="n">y_true_</span><span class="p">,</span> <span class="n">y_pred_</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">accuracy</span>


<span class="k">def</span> <span class="nf">my_f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
<span class="c1">#     print(&#34;my_f1_score&#34;)</span>
<span class="c1">#     print(f&#34;y_true:{y_true}, y_pred:{y_pred}&#34;)</span>
    
    <span class="n">y_true_</span><span class="p">,</span> <span class="n">y_pred_</span> <span class="o">=</span> <span class="n">tarnsform_metrics</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="c1">#     print(f&#34;y_true_:{y_true_}, y_pred_:{y_pred_}&#34;)</span>

    <span class="k">return</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_true_</span><span class="p">,</span> <span class="n">y_pred_</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><h2 id="模型定义">模型定义</h2>
<p>在编译模型时指定自定义loss函数，keras 会自动对两个输出目标分别使用该自定义loss函数，最后模型算的是这两个loss之和：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">get_model</span><span class="p">():</span>
    <span class="n">K</span><span class="o">.</span><span class="n">clear_session</span><span class="p">()</span>
    
    <span class="n">bert_model</span> <span class="o">=</span> <span class="n">TFBertForPreTraining</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">bert_path</span><span class="p">,</span> <span class="n">from_pt</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
 
    <span class="n">input_ids</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;int32&#39;</span><span class="p">)</span>
    <span class="n">input_token_type_ids</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;int32&#39;</span><span class="p">)</span>
    <span class="n">input_attention_mask</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;int32&#39;</span><span class="p">)</span>
 
    <span class="n">bert_output</span> <span class="o">=</span> <span class="n">bert_model</span><span class="p">({</span><span class="s1">&#39;input_ids&#39;</span><span class="p">:</span><span class="n">input_ids</span><span class="p">,</span> <span class="s1">&#39;token_type_ids&#39;</span><span class="p">:</span><span class="n">input_token_type_ids</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">:</span><span class="n">input_attention_mask</span><span class="p">},</span> <span class="n">return_dict</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">projection_logits</span> <span class="o">=</span> <span class="n">bert_output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">bert_cls</span> <span class="o">=</span> <span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])(</span><span class="n">projection_logits</span><span class="p">)</span> <span class="c1"># 取出[CLS]对应的向量用来做分类</span>
    
    <span class="n">dropout_A</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)(</span><span class="n">bert_cls</span><span class="p">)</span>
    <span class="n">output_A</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">)(</span><span class="n">dropout_A</span><span class="p">)</span>
    
    <span class="n">dropout_B</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)(</span><span class="n">bert_cls</span><span class="p">)</span>
    <span class="n">output_B</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">)(</span><span class="n">dropout_B</span><span class="p">)</span>
 
    <span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">([</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">input_token_type_ids</span><span class="p">,</span> <span class="n">input_attention_mask</span><span class="p">],</span> <span class="p">[</span><span class="n">output_A</span><span class="p">,</span> <span class="n">output_B</span><span class="p">])</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
                  <span class="n">loss</span><span class="o">=</span><span class="n">my_binary_crossentropy</span><span class="p">,</span>
<span class="c1">#                   loss=&#39;binary_crossentropy&#39;,</span>
<span class="c1">#                   loss=binary_crossentropy,</span>
                  <span class="n">optimizer</span><span class="o">=</span><span class="n">Adam</span><span class="p">(</span><span class="mf">1e-5</span><span class="p">),</span>    <span class="c1">#用足够小的学习率</span>
                  <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">my_binary_accuracy</span><span class="p">,</span> <span class="n">my_f1_score</span><span class="p">]</span>
<span class="c1">#                   metrics=&#39;accuracy&#39;</span>
                 <span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">model</span>
</code></pre></td></tr></table>
</div>
</div><h2 id="tip">TIP：</h2>
<ol>
<li>在处理数据时，若labelB==1，则labelA=1；若labelA==0，则labelB=0 。</li>
</ol>
<hr>
<h2 id="附录">附录</h2>
<h3 id="全部源码">全部源码</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">   1
</span><span class="lnt">   2
</span><span class="lnt">   3
</span><span class="lnt">   4
</span><span class="lnt">   5
</span><span class="lnt">   6
</span><span class="lnt">   7
</span><span class="lnt">   8
</span><span class="lnt">   9
</span><span class="lnt">  10
</span><span class="lnt">  11
</span><span class="lnt">  12
</span><span class="lnt">  13
</span><span class="lnt">  14
</span><span class="lnt">  15
</span><span class="lnt">  16
</span><span class="lnt">  17
</span><span class="lnt">  18
</span><span class="lnt">  19
</span><span class="lnt">  20
</span><span class="lnt">  21
</span><span class="lnt">  22
</span><span class="lnt">  23
</span><span class="lnt">  24
</span><span class="lnt">  25
</span><span class="lnt">  26
</span><span class="lnt">  27
</span><span class="lnt">  28
</span><span class="lnt">  29
</span><span class="lnt">  30
</span><span class="lnt">  31
</span><span class="lnt">  32
</span><span class="lnt">  33
</span><span class="lnt">  34
</span><span class="lnt">  35
</span><span class="lnt">  36
</span><span class="lnt">  37
</span><span class="lnt">  38
</span><span class="lnt">  39
</span><span class="lnt">  40
</span><span class="lnt">  41
</span><span class="lnt">  42
</span><span class="lnt">  43
</span><span class="lnt">  44
</span><span class="lnt">  45
</span><span class="lnt">  46
</span><span class="lnt">  47
</span><span class="lnt">  48
</span><span class="lnt">  49
</span><span class="lnt">  50
</span><span class="lnt">  51
</span><span class="lnt">  52
</span><span class="lnt">  53
</span><span class="lnt">  54
</span><span class="lnt">  55
</span><span class="lnt">  56
</span><span class="lnt">  57
</span><span class="lnt">  58
</span><span class="lnt">  59
</span><span class="lnt">  60
</span><span class="lnt">  61
</span><span class="lnt">  62
</span><span class="lnt">  63
</span><span class="lnt">  64
</span><span class="lnt">  65
</span><span class="lnt">  66
</span><span class="lnt">  67
</span><span class="lnt">  68
</span><span class="lnt">  69
</span><span class="lnt">  70
</span><span class="lnt">  71
</span><span class="lnt">  72
</span><span class="lnt">  73
</span><span class="lnt">  74
</span><span class="lnt">  75
</span><span class="lnt">  76
</span><span class="lnt">  77
</span><span class="lnt">  78
</span><span class="lnt">  79
</span><span class="lnt">  80
</span><span class="lnt">  81
</span><span class="lnt">  82
</span><span class="lnt">  83
</span><span class="lnt">  84
</span><span class="lnt">  85
</span><span class="lnt">  86
</span><span class="lnt">  87
</span><span class="lnt">  88
</span><span class="lnt">  89
</span><span class="lnt">  90
</span><span class="lnt">  91
</span><span class="lnt">  92
</span><span class="lnt">  93
</span><span class="lnt">  94
</span><span class="lnt">  95
</span><span class="lnt">  96
</span><span class="lnt">  97
</span><span class="lnt">  98
</span><span class="lnt">  99
</span><span class="lnt"> 100
</span><span class="lnt"> 101
</span><span class="lnt"> 102
</span><span class="lnt"> 103
</span><span class="lnt"> 104
</span><span class="lnt"> 105
</span><span class="lnt"> 106
</span><span class="lnt"> 107
</span><span class="lnt"> 108
</span><span class="lnt"> 109
</span><span class="lnt"> 110
</span><span class="lnt"> 111
</span><span class="lnt"> 112
</span><span class="lnt"> 113
</span><span class="lnt"> 114
</span><span class="lnt"> 115
</span><span class="lnt"> 116
</span><span class="lnt"> 117
</span><span class="lnt"> 118
</span><span class="lnt"> 119
</span><span class="lnt"> 120
</span><span class="lnt"> 121
</span><span class="lnt"> 122
</span><span class="lnt"> 123
</span><span class="lnt"> 124
</span><span class="lnt"> 125
</span><span class="lnt"> 126
</span><span class="lnt"> 127
</span><span class="lnt"> 128
</span><span class="lnt"> 129
</span><span class="lnt"> 130
</span><span class="lnt"> 131
</span><span class="lnt"> 132
</span><span class="lnt"> 133
</span><span class="lnt"> 134
</span><span class="lnt"> 135
</span><span class="lnt"> 136
</span><span class="lnt"> 137
</span><span class="lnt"> 138
</span><span class="lnt"> 139
</span><span class="lnt"> 140
</span><span class="lnt"> 141
</span><span class="lnt"> 142
</span><span class="lnt"> 143
</span><span class="lnt"> 144
</span><span class="lnt"> 145
</span><span class="lnt"> 146
</span><span class="lnt"> 147
</span><span class="lnt"> 148
</span><span class="lnt"> 149
</span><span class="lnt"> 150
</span><span class="lnt"> 151
</span><span class="lnt"> 152
</span><span class="lnt"> 153
</span><span class="lnt"> 154
</span><span class="lnt"> 155
</span><span class="lnt"> 156
</span><span class="lnt"> 157
</span><span class="lnt"> 158
</span><span class="lnt"> 159
</span><span class="lnt"> 160
</span><span class="lnt"> 161
</span><span class="lnt"> 162
</span><span class="lnt"> 163
</span><span class="lnt"> 164
</span><span class="lnt"> 165
</span><span class="lnt"> 166
</span><span class="lnt"> 167
</span><span class="lnt"> 168
</span><span class="lnt"> 169
</span><span class="lnt"> 170
</span><span class="lnt"> 171
</span><span class="lnt"> 172
</span><span class="lnt"> 173
</span><span class="lnt"> 174
</span><span class="lnt"> 175
</span><span class="lnt"> 176
</span><span class="lnt"> 177
</span><span class="lnt"> 178
</span><span class="lnt"> 179
</span><span class="lnt"> 180
</span><span class="lnt"> 181
</span><span class="lnt"> 182
</span><span class="lnt"> 183
</span><span class="lnt"> 184
</span><span class="lnt"> 185
</span><span class="lnt"> 186
</span><span class="lnt"> 187
</span><span class="lnt"> 188
</span><span class="lnt"> 189
</span><span class="lnt"> 190
</span><span class="lnt"> 191
</span><span class="lnt"> 192
</span><span class="lnt"> 193
</span><span class="lnt"> 194
</span><span class="lnt"> 195
</span><span class="lnt"> 196
</span><span class="lnt"> 197
</span><span class="lnt"> 198
</span><span class="lnt"> 199
</span><span class="lnt"> 200
</span><span class="lnt"> 201
</span><span class="lnt"> 202
</span><span class="lnt"> 203
</span><span class="lnt"> 204
</span><span class="lnt"> 205
</span><span class="lnt"> 206
</span><span class="lnt"> 207
</span><span class="lnt"> 208
</span><span class="lnt"> 209
</span><span class="lnt"> 210
</span><span class="lnt"> 211
</span><span class="lnt"> 212
</span><span class="lnt"> 213
</span><span class="lnt"> 214
</span><span class="lnt"> 215
</span><span class="lnt"> 216
</span><span class="lnt"> 217
</span><span class="lnt"> 218
</span><span class="lnt"> 219
</span><span class="lnt"> 220
</span><span class="lnt"> 221
</span><span class="lnt"> 222
</span><span class="lnt"> 223
</span><span class="lnt"> 224
</span><span class="lnt"> 225
</span><span class="lnt"> 226
</span><span class="lnt"> 227
</span><span class="lnt"> 228
</span><span class="lnt"> 229
</span><span class="lnt"> 230
</span><span class="lnt"> 231
</span><span class="lnt"> 232
</span><span class="lnt"> 233
</span><span class="lnt"> 234
</span><span class="lnt"> 235
</span><span class="lnt"> 236
</span><span class="lnt"> 237
</span><span class="lnt"> 238
</span><span class="lnt"> 239
</span><span class="lnt"> 240
</span><span class="lnt"> 241
</span><span class="lnt"> 242
</span><span class="lnt"> 243
</span><span class="lnt"> 244
</span><span class="lnt"> 245
</span><span class="lnt"> 246
</span><span class="lnt"> 247
</span><span class="lnt"> 248
</span><span class="lnt"> 249
</span><span class="lnt"> 250
</span><span class="lnt"> 251
</span><span class="lnt"> 252
</span><span class="lnt"> 253
</span><span class="lnt"> 254
</span><span class="lnt"> 255
</span><span class="lnt"> 256
</span><span class="lnt"> 257
</span><span class="lnt"> 258
</span><span class="lnt"> 259
</span><span class="lnt"> 260
</span><span class="lnt"> 261
</span><span class="lnt"> 262
</span><span class="lnt"> 263
</span><span class="lnt"> 264
</span><span class="lnt"> 265
</span><span class="lnt"> 266
</span><span class="lnt"> 267
</span><span class="lnt"> 268
</span><span class="lnt"> 269
</span><span class="lnt"> 270
</span><span class="lnt"> 271
</span><span class="lnt"> 272
</span><span class="lnt"> 273
</span><span class="lnt"> 274
</span><span class="lnt"> 275
</span><span class="lnt"> 276
</span><span class="lnt"> 277
</span><span class="lnt"> 278
</span><span class="lnt"> 279
</span><span class="lnt"> 280
</span><span class="lnt"> 281
</span><span class="lnt"> 282
</span><span class="lnt"> 283
</span><span class="lnt"> 284
</span><span class="lnt"> 285
</span><span class="lnt"> 286
</span><span class="lnt"> 287
</span><span class="lnt"> 288
</span><span class="lnt"> 289
</span><span class="lnt"> 290
</span><span class="lnt"> 291
</span><span class="lnt"> 292
</span><span class="lnt"> 293
</span><span class="lnt"> 294
</span><span class="lnt"> 295
</span><span class="lnt"> 296
</span><span class="lnt"> 297
</span><span class="lnt"> 298
</span><span class="lnt"> 299
</span><span class="lnt"> 300
</span><span class="lnt"> 301
</span><span class="lnt"> 302
</span><span class="lnt"> 303
</span><span class="lnt"> 304
</span><span class="lnt"> 305
</span><span class="lnt"> 306
</span><span class="lnt"> 307
</span><span class="lnt"> 308
</span><span class="lnt"> 309
</span><span class="lnt"> 310
</span><span class="lnt"> 311
</span><span class="lnt"> 312
</span><span class="lnt"> 313
</span><span class="lnt"> 314
</span><span class="lnt"> 315
</span><span class="lnt"> 316
</span><span class="lnt"> 317
</span><span class="lnt"> 318
</span><span class="lnt"> 319
</span><span class="lnt"> 320
</span><span class="lnt"> 321
</span><span class="lnt"> 322
</span><span class="lnt"> 323
</span><span class="lnt"> 324
</span><span class="lnt"> 325
</span><span class="lnt"> 326
</span><span class="lnt"> 327
</span><span class="lnt"> 328
</span><span class="lnt"> 329
</span><span class="lnt"> 330
</span><span class="lnt"> 331
</span><span class="lnt"> 332
</span><span class="lnt"> 333
</span><span class="lnt"> 334
</span><span class="lnt"> 335
</span><span class="lnt"> 336
</span><span class="lnt"> 337
</span><span class="lnt"> 338
</span><span class="lnt"> 339
</span><span class="lnt"> 340
</span><span class="lnt"> 341
</span><span class="lnt"> 342
</span><span class="lnt"> 343
</span><span class="lnt"> 344
</span><span class="lnt"> 345
</span><span class="lnt"> 346
</span><span class="lnt"> 347
</span><span class="lnt"> 348
</span><span class="lnt"> 349
</span><span class="lnt"> 350
</span><span class="lnt"> 351
</span><span class="lnt"> 352
</span><span class="lnt"> 353
</span><span class="lnt"> 354
</span><span class="lnt"> 355
</span><span class="lnt"> 356
</span><span class="lnt"> 357
</span><span class="lnt"> 358
</span><span class="lnt"> 359
</span><span class="lnt"> 360
</span><span class="lnt"> 361
</span><span class="lnt"> 362
</span><span class="lnt"> 363
</span><span class="lnt"> 364
</span><span class="lnt"> 365
</span><span class="lnt"> 366
</span><span class="lnt"> 367
</span><span class="lnt"> 368
</span><span class="lnt"> 369
</span><span class="lnt"> 370
</span><span class="lnt"> 371
</span><span class="lnt"> 372
</span><span class="lnt"> 373
</span><span class="lnt"> 374
</span><span class="lnt"> 375
</span><span class="lnt"> 376
</span><span class="lnt"> 377
</span><span class="lnt"> 378
</span><span class="lnt"> 379
</span><span class="lnt"> 380
</span><span class="lnt"> 381
</span><span class="lnt"> 382
</span><span class="lnt"> 383
</span><span class="lnt"> 384
</span><span class="lnt"> 385
</span><span class="lnt"> 386
</span><span class="lnt"> 387
</span><span class="lnt"> 388
</span><span class="lnt"> 389
</span><span class="lnt"> 390
</span><span class="lnt"> 391
</span><span class="lnt"> 392
</span><span class="lnt"> 393
</span><span class="lnt"> 394
</span><span class="lnt"> 395
</span><span class="lnt"> 396
</span><span class="lnt"> 397
</span><span class="lnt"> 398
</span><span class="lnt"> 399
</span><span class="lnt"> 400
</span><span class="lnt"> 401
</span><span class="lnt"> 402
</span><span class="lnt"> 403
</span><span class="lnt"> 404
</span><span class="lnt"> 405
</span><span class="lnt"> 406
</span><span class="lnt"> 407
</span><span class="lnt"> 408
</span><span class="lnt"> 409
</span><span class="lnt"> 410
</span><span class="lnt"> 411
</span><span class="lnt"> 412
</span><span class="lnt"> 413
</span><span class="lnt"> 414
</span><span class="lnt"> 415
</span><span class="lnt"> 416
</span><span class="lnt"> 417
</span><span class="lnt"> 418
</span><span class="lnt"> 419
</span><span class="lnt"> 420
</span><span class="lnt"> 421
</span><span class="lnt"> 422
</span><span class="lnt"> 423
</span><span class="lnt"> 424
</span><span class="lnt"> 425
</span><span class="lnt"> 426
</span><span class="lnt"> 427
</span><span class="lnt"> 428
</span><span class="lnt"> 429
</span><span class="lnt"> 430
</span><span class="lnt"> 431
</span><span class="lnt"> 432
</span><span class="lnt"> 433
</span><span class="lnt"> 434
</span><span class="lnt"> 435
</span><span class="lnt"> 436
</span><span class="lnt"> 437
</span><span class="lnt"> 438
</span><span class="lnt"> 439
</span><span class="lnt"> 440
</span><span class="lnt"> 441
</span><span class="lnt"> 442
</span><span class="lnt"> 443
</span><span class="lnt"> 444
</span><span class="lnt"> 445
</span><span class="lnt"> 446
</span><span class="lnt"> 447
</span><span class="lnt"> 448
</span><span class="lnt"> 449
</span><span class="lnt"> 450
</span><span class="lnt"> 451
</span><span class="lnt"> 452
</span><span class="lnt"> 453
</span><span class="lnt"> 454
</span><span class="lnt"> 455
</span><span class="lnt"> 456
</span><span class="lnt"> 457
</span><span class="lnt"> 458
</span><span class="lnt"> 459
</span><span class="lnt"> 460
</span><span class="lnt"> 461
</span><span class="lnt"> 462
</span><span class="lnt"> 463
</span><span class="lnt"> 464
</span><span class="lnt"> 465
</span><span class="lnt"> 466
</span><span class="lnt"> 467
</span><span class="lnt"> 468
</span><span class="lnt"> 469
</span><span class="lnt"> 470
</span><span class="lnt"> 471
</span><span class="lnt"> 472
</span><span class="lnt"> 473
</span><span class="lnt"> 474
</span><span class="lnt"> 475
</span><span class="lnt"> 476
</span><span class="lnt"> 477
</span><span class="lnt"> 478
</span><span class="lnt"> 479
</span><span class="lnt"> 480
</span><span class="lnt"> 481
</span><span class="lnt"> 482
</span><span class="lnt"> 483
</span><span class="lnt"> 484
</span><span class="lnt"> 485
</span><span class="lnt"> 486
</span><span class="lnt"> 487
</span><span class="lnt"> 488
</span><span class="lnt"> 489
</span><span class="lnt"> 490
</span><span class="lnt"> 491
</span><span class="lnt"> 492
</span><span class="lnt"> 493
</span><span class="lnt"> 494
</span><span class="lnt"> 495
</span><span class="lnt"> 496
</span><span class="lnt"> 497
</span><span class="lnt"> 498
</span><span class="lnt"> 499
</span><span class="lnt"> 500
</span><span class="lnt"> 501
</span><span class="lnt"> 502
</span><span class="lnt"> 503
</span><span class="lnt"> 504
</span><span class="lnt"> 505
</span><span class="lnt"> 506
</span><span class="lnt"> 507
</span><span class="lnt"> 508
</span><span class="lnt"> 509
</span><span class="lnt"> 510
</span><span class="lnt"> 511
</span><span class="lnt"> 512
</span><span class="lnt"> 513
</span><span class="lnt"> 514
</span><span class="lnt"> 515
</span><span class="lnt"> 516
</span><span class="lnt"> 517
</span><span class="lnt"> 518
</span><span class="lnt"> 519
</span><span class="lnt"> 520
</span><span class="lnt"> 521
</span><span class="lnt"> 522
</span><span class="lnt"> 523
</span><span class="lnt"> 524
</span><span class="lnt"> 525
</span><span class="lnt"> 526
</span><span class="lnt"> 527
</span><span class="lnt"> 528
</span><span class="lnt"> 529
</span><span class="lnt"> 530
</span><span class="lnt"> 531
</span><span class="lnt"> 532
</span><span class="lnt"> 533
</span><span class="lnt"> 534
</span><span class="lnt"> 535
</span><span class="lnt"> 536
</span><span class="lnt"> 537
</span><span class="lnt"> 538
</span><span class="lnt"> 539
</span><span class="lnt"> 540
</span><span class="lnt"> 541
</span><span class="lnt"> 542
</span><span class="lnt"> 543
</span><span class="lnt"> 544
</span><span class="lnt"> 545
</span><span class="lnt"> 546
</span><span class="lnt"> 547
</span><span class="lnt"> 548
</span><span class="lnt"> 549
</span><span class="lnt"> 550
</span><span class="lnt"> 551
</span><span class="lnt"> 552
</span><span class="lnt"> 553
</span><span class="lnt"> 554
</span><span class="lnt"> 555
</span><span class="lnt"> 556
</span><span class="lnt"> 557
</span><span class="lnt"> 558
</span><span class="lnt"> 559
</span><span class="lnt"> 560
</span><span class="lnt"> 561
</span><span class="lnt"> 562
</span><span class="lnt"> 563
</span><span class="lnt"> 564
</span><span class="lnt"> 565
</span><span class="lnt"> 566
</span><span class="lnt"> 567
</span><span class="lnt"> 568
</span><span class="lnt"> 569
</span><span class="lnt"> 570
</span><span class="lnt"> 571
</span><span class="lnt"> 572
</span><span class="lnt"> 573
</span><span class="lnt"> 574
</span><span class="lnt"> 575
</span><span class="lnt"> 576
</span><span class="lnt"> 577
</span><span class="lnt"> 578
</span><span class="lnt"> 579
</span><span class="lnt"> 580
</span><span class="lnt"> 581
</span><span class="lnt"> 582
</span><span class="lnt"> 583
</span><span class="lnt"> 584
</span><span class="lnt"> 585
</span><span class="lnt"> 586
</span><span class="lnt"> 587
</span><span class="lnt"> 588
</span><span class="lnt"> 589
</span><span class="lnt"> 590
</span><span class="lnt"> 591
</span><span class="lnt"> 592
</span><span class="lnt"> 593
</span><span class="lnt"> 594
</span><span class="lnt"> 595
</span><span class="lnt"> 596
</span><span class="lnt"> 597
</span><span class="lnt"> 598
</span><span class="lnt"> 599
</span><span class="lnt"> 600
</span><span class="lnt"> 601
</span><span class="lnt"> 602
</span><span class="lnt"> 603
</span><span class="lnt"> 604
</span><span class="lnt"> 605
</span><span class="lnt"> 606
</span><span class="lnt"> 607
</span><span class="lnt"> 608
</span><span class="lnt"> 609
</span><span class="lnt"> 610
</span><span class="lnt"> 611
</span><span class="lnt"> 612
</span><span class="lnt"> 613
</span><span class="lnt"> 614
</span><span class="lnt"> 615
</span><span class="lnt"> 616
</span><span class="lnt"> 617
</span><span class="lnt"> 618
</span><span class="lnt"> 619
</span><span class="lnt"> 620
</span><span class="lnt"> 621
</span><span class="lnt"> 622
</span><span class="lnt"> 623
</span><span class="lnt"> 624
</span><span class="lnt"> 625
</span><span class="lnt"> 626
</span><span class="lnt"> 627
</span><span class="lnt"> 628
</span><span class="lnt"> 629
</span><span class="lnt"> 630
</span><span class="lnt"> 631
</span><span class="lnt"> 632
</span><span class="lnt"> 633
</span><span class="lnt"> 634
</span><span class="lnt"> 635
</span><span class="lnt"> 636
</span><span class="lnt"> 637
</span><span class="lnt"> 638
</span><span class="lnt"> 639
</span><span class="lnt"> 640
</span><span class="lnt"> 641
</span><span class="lnt"> 642
</span><span class="lnt"> 643
</span><span class="lnt"> 644
</span><span class="lnt"> 645
</span><span class="lnt"> 646
</span><span class="lnt"> 647
</span><span class="lnt"> 648
</span><span class="lnt"> 649
</span><span class="lnt"> 650
</span><span class="lnt"> 651
</span><span class="lnt"> 652
</span><span class="lnt"> 653
</span><span class="lnt"> 654
</span><span class="lnt"> 655
</span><span class="lnt"> 656
</span><span class="lnt"> 657
</span><span class="lnt"> 658
</span><span class="lnt"> 659
</span><span class="lnt"> 660
</span><span class="lnt"> 661
</span><span class="lnt"> 662
</span><span class="lnt"> 663
</span><span class="lnt"> 664
</span><span class="lnt"> 665
</span><span class="lnt"> 666
</span><span class="lnt"> 667
</span><span class="lnt"> 668
</span><span class="lnt"> 669
</span><span class="lnt"> 670
</span><span class="lnt"> 671
</span><span class="lnt"> 672
</span><span class="lnt"> 673
</span><span class="lnt"> 674
</span><span class="lnt"> 675
</span><span class="lnt"> 676
</span><span class="lnt"> 677
</span><span class="lnt"> 678
</span><span class="lnt"> 679
</span><span class="lnt"> 680
</span><span class="lnt"> 681
</span><span class="lnt"> 682
</span><span class="lnt"> 683
</span><span class="lnt"> 684
</span><span class="lnt"> 685
</span><span class="lnt"> 686
</span><span class="lnt"> 687
</span><span class="lnt"> 688
</span><span class="lnt"> 689
</span><span class="lnt"> 690
</span><span class="lnt"> 691
</span><span class="lnt"> 692
</span><span class="lnt"> 693
</span><span class="lnt"> 694
</span><span class="lnt"> 695
</span><span class="lnt"> 696
</span><span class="lnt"> 697
</span><span class="lnt"> 698
</span><span class="lnt"> 699
</span><span class="lnt"> 700
</span><span class="lnt"> 701
</span><span class="lnt"> 702
</span><span class="lnt"> 703
</span><span class="lnt"> 704
</span><span class="lnt"> 705
</span><span class="lnt"> 706
</span><span class="lnt"> 707
</span><span class="lnt"> 708
</span><span class="lnt"> 709
</span><span class="lnt"> 710
</span><span class="lnt"> 711
</span><span class="lnt"> 712
</span><span class="lnt"> 713
</span><span class="lnt"> 714
</span><span class="lnt"> 715
</span><span class="lnt"> 716
</span><span class="lnt"> 717
</span><span class="lnt"> 718
</span><span class="lnt"> 719
</span><span class="lnt"> 720
</span><span class="lnt"> 721
</span><span class="lnt"> 722
</span><span class="lnt"> 723
</span><span class="lnt"> 724
</span><span class="lnt"> 725
</span><span class="lnt"> 726
</span><span class="lnt"> 727
</span><span class="lnt"> 728
</span><span class="lnt"> 729
</span><span class="lnt"> 730
</span><span class="lnt"> 731
</span><span class="lnt"> 732
</span><span class="lnt"> 733
</span><span class="lnt"> 734
</span><span class="lnt"> 735
</span><span class="lnt"> 736
</span><span class="lnt"> 737
</span><span class="lnt"> 738
</span><span class="lnt"> 739
</span><span class="lnt"> 740
</span><span class="lnt"> 741
</span><span class="lnt"> 742
</span><span class="lnt"> 743
</span><span class="lnt"> 744
</span><span class="lnt"> 745
</span><span class="lnt"> 746
</span><span class="lnt"> 747
</span><span class="lnt"> 748
</span><span class="lnt"> 749
</span><span class="lnt"> 750
</span><span class="lnt"> 751
</span><span class="lnt"> 752
</span><span class="lnt"> 753
</span><span class="lnt"> 754
</span><span class="lnt"> 755
</span><span class="lnt"> 756
</span><span class="lnt"> 757
</span><span class="lnt"> 758
</span><span class="lnt"> 759
</span><span class="lnt"> 760
</span><span class="lnt"> 761
</span><span class="lnt"> 762
</span><span class="lnt"> 763
</span><span class="lnt"> 764
</span><span class="lnt"> 765
</span><span class="lnt"> 766
</span><span class="lnt"> 767
</span><span class="lnt"> 768
</span><span class="lnt"> 769
</span><span class="lnt"> 770
</span><span class="lnt"> 771
</span><span class="lnt"> 772
</span><span class="lnt"> 773
</span><span class="lnt"> 774
</span><span class="lnt"> 775
</span><span class="lnt"> 776
</span><span class="lnt"> 777
</span><span class="lnt"> 778
</span><span class="lnt"> 779
</span><span class="lnt"> 780
</span><span class="lnt"> 781
</span><span class="lnt"> 782
</span><span class="lnt"> 783
</span><span class="lnt"> 784
</span><span class="lnt"> 785
</span><span class="lnt"> 786
</span><span class="lnt"> 787
</span><span class="lnt"> 788
</span><span class="lnt"> 789
</span><span class="lnt"> 790
</span><span class="lnt"> 791
</span><span class="lnt"> 792
</span><span class="lnt"> 793
</span><span class="lnt"> 794
</span><span class="lnt"> 795
</span><span class="lnt"> 796
</span><span class="lnt"> 797
</span><span class="lnt"> 798
</span><span class="lnt"> 799
</span><span class="lnt"> 800
</span><span class="lnt"> 801
</span><span class="lnt"> 802
</span><span class="lnt"> 803
</span><span class="lnt"> 804
</span><span class="lnt"> 805
</span><span class="lnt"> 806
</span><span class="lnt"> 807
</span><span class="lnt"> 808
</span><span class="lnt"> 809
</span><span class="lnt"> 810
</span><span class="lnt"> 811
</span><span class="lnt"> 812
</span><span class="lnt"> 813
</span><span class="lnt"> 814
</span><span class="lnt"> 815
</span><span class="lnt"> 816
</span><span class="lnt"> 817
</span><span class="lnt"> 818
</span><span class="lnt"> 819
</span><span class="lnt"> 820
</span><span class="lnt"> 821
</span><span class="lnt"> 822
</span><span class="lnt"> 823
</span><span class="lnt"> 824
</span><span class="lnt"> 825
</span><span class="lnt"> 826
</span><span class="lnt"> 827
</span><span class="lnt"> 828
</span><span class="lnt"> 829
</span><span class="lnt"> 830
</span><span class="lnt"> 831
</span><span class="lnt"> 832
</span><span class="lnt"> 833
</span><span class="lnt"> 834
</span><span class="lnt"> 835
</span><span class="lnt"> 836
</span><span class="lnt"> 837
</span><span class="lnt"> 838
</span><span class="lnt"> 839
</span><span class="lnt"> 840
</span><span class="lnt"> 841
</span><span class="lnt"> 842
</span><span class="lnt"> 843
</span><span class="lnt"> 844
</span><span class="lnt"> 845
</span><span class="lnt"> 846
</span><span class="lnt"> 847
</span><span class="lnt"> 848
</span><span class="lnt"> 849
</span><span class="lnt"> 850
</span><span class="lnt"> 851
</span><span class="lnt"> 852
</span><span class="lnt"> 853
</span><span class="lnt"> 854
</span><span class="lnt"> 855
</span><span class="lnt"> 856
</span><span class="lnt"> 857
</span><span class="lnt"> 858
</span><span class="lnt"> 859
</span><span class="lnt"> 860
</span><span class="lnt"> 861
</span><span class="lnt"> 862
</span><span class="lnt"> 863
</span><span class="lnt"> 864
</span><span class="lnt"> 865
</span><span class="lnt"> 866
</span><span class="lnt"> 867
</span><span class="lnt"> 868
</span><span class="lnt"> 869
</span><span class="lnt"> 870
</span><span class="lnt"> 871
</span><span class="lnt"> 872
</span><span class="lnt"> 873
</span><span class="lnt"> 874
</span><span class="lnt"> 875
</span><span class="lnt"> 876
</span><span class="lnt"> 877
</span><span class="lnt"> 878
</span><span class="lnt"> 879
</span><span class="lnt"> 880
</span><span class="lnt"> 881
</span><span class="lnt"> 882
</span><span class="lnt"> 883
</span><span class="lnt"> 884
</span><span class="lnt"> 885
</span><span class="lnt"> 886
</span><span class="lnt"> 887
</span><span class="lnt"> 888
</span><span class="lnt"> 889
</span><span class="lnt"> 890
</span><span class="lnt"> 891
</span><span class="lnt"> 892
</span><span class="lnt"> 893
</span><span class="lnt"> 894
</span><span class="lnt"> 895
</span><span class="lnt"> 896
</span><span class="lnt"> 897
</span><span class="lnt"> 898
</span><span class="lnt"> 899
</span><span class="lnt"> 900
</span><span class="lnt"> 901
</span><span class="lnt"> 902
</span><span class="lnt"> 903
</span><span class="lnt"> 904
</span><span class="lnt"> 905
</span><span class="lnt"> 906
</span><span class="lnt"> 907
</span><span class="lnt"> 908
</span><span class="lnt"> 909
</span><span class="lnt"> 910
</span><span class="lnt"> 911
</span><span class="lnt"> 912
</span><span class="lnt"> 913
</span><span class="lnt"> 914
</span><span class="lnt"> 915
</span><span class="lnt"> 916
</span><span class="lnt"> 917
</span><span class="lnt"> 918
</span><span class="lnt"> 919
</span><span class="lnt"> 920
</span><span class="lnt"> 921
</span><span class="lnt"> 922
</span><span class="lnt"> 923
</span><span class="lnt"> 924
</span><span class="lnt"> 925
</span><span class="lnt"> 926
</span><span class="lnt"> 927
</span><span class="lnt"> 928
</span><span class="lnt"> 929
</span><span class="lnt"> 930
</span><span class="lnt"> 931
</span><span class="lnt"> 932
</span><span class="lnt"> 933
</span><span class="lnt"> 934
</span><span class="lnt"> 935
</span><span class="lnt"> 936
</span><span class="lnt"> 937
</span><span class="lnt"> 938
</span><span class="lnt"> 939
</span><span class="lnt"> 940
</span><span class="lnt"> 941
</span><span class="lnt"> 942
</span><span class="lnt"> 943
</span><span class="lnt"> 944
</span><span class="lnt"> 945
</span><span class="lnt"> 946
</span><span class="lnt"> 947
</span><span class="lnt"> 948
</span><span class="lnt"> 949
</span><span class="lnt"> 950
</span><span class="lnt"> 951
</span><span class="lnt"> 952
</span><span class="lnt"> 953
</span><span class="lnt"> 954
</span><span class="lnt"> 955
</span><span class="lnt"> 956
</span><span class="lnt"> 957
</span><span class="lnt"> 958
</span><span class="lnt"> 959
</span><span class="lnt"> 960
</span><span class="lnt"> 961
</span><span class="lnt"> 962
</span><span class="lnt"> 963
</span><span class="lnt"> 964
</span><span class="lnt"> 965
</span><span class="lnt"> 966
</span><span class="lnt"> 967
</span><span class="lnt"> 968
</span><span class="lnt"> 969
</span><span class="lnt"> 970
</span><span class="lnt"> 971
</span><span class="lnt"> 972
</span><span class="lnt"> 973
</span><span class="lnt"> 974
</span><span class="lnt"> 975
</span><span class="lnt"> 976
</span><span class="lnt"> 977
</span><span class="lnt"> 978
</span><span class="lnt"> 979
</span><span class="lnt"> 980
</span><span class="lnt"> 981
</span><span class="lnt"> 982
</span><span class="lnt"> 983
</span><span class="lnt"> 984
</span><span class="lnt"> 985
</span><span class="lnt"> 986
</span><span class="lnt"> 987
</span><span class="lnt"> 988
</span><span class="lnt"> 989
</span><span class="lnt"> 990
</span><span class="lnt"> 991
</span><span class="lnt"> 992
</span><span class="lnt"> 993
</span><span class="lnt"> 994
</span><span class="lnt"> 995
</span><span class="lnt"> 996
</span><span class="lnt"> 997
</span><span class="lnt"> 998
</span><span class="lnt"> 999
</span><span class="lnt">1000
</span><span class="lnt">1001
</span><span class="lnt">1002
</span><span class="lnt">1003
</span><span class="lnt">1004
</span><span class="lnt">1005
</span><span class="lnt">1006
</span><span class="lnt">1007
</span><span class="lnt">1008
</span><span class="lnt">1009
</span><span class="lnt">1010
</span><span class="lnt">1011
</span><span class="lnt">1012
</span><span class="lnt">1013
</span><span class="lnt">1014
</span><span class="lnt">1015
</span><span class="lnt">1016
</span><span class="lnt">1017
</span><span class="lnt">1018
</span><span class="lnt">1019
</span><span class="lnt">1020
</span><span class="lnt">1021
</span><span class="lnt">1022
</span><span class="lnt">1023
</span><span class="lnt">1024
</span><span class="lnt">1025
</span><span class="lnt">1026
</span><span class="lnt">1027
</span><span class="lnt">1028
</span><span class="lnt">1029
</span><span class="lnt">1030
</span><span class="lnt">1031
</span><span class="lnt">1032
</span><span class="lnt">1033
</span><span class="lnt">1034
</span><span class="lnt">1035
</span><span class="lnt">1036
</span><span class="lnt">1037
</span><span class="lnt">1038
</span><span class="lnt">1039
</span><span class="lnt">1040
</span><span class="lnt">1041
</span><span class="lnt">1042
</span><span class="lnt">1043
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-markdown" data-lang="markdown"><span class="gh"># 导包
</span><span class="gh"></span>

<span class="s">```python
</span><span class="s"></span><span class="kn">import</span> <span class="nn">os</span>
<span class="c1"># os.environ[&#34;TF_CPP_MIN_LOG_LEVEL&#34;] = &#34;3&#34;</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">json</span>

<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow.keras</span> <span class="kn">as</span> <span class="nn">keras</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">run_functions_eagerly</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
<span class="n">tf</span><span class="o">.</span><span class="n">get_logger</span><span class="p">()</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">ERROR</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">keras.metrics</span> <span class="kn">import</span> <span class="n">top_k_categorical_accuracy</span><span class="p">,</span> <span class="n">binary_accuracy</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">keras.callbacks</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">load_model</span>
<span class="kn">import</span> <span class="nn">keras.backend</span> <span class="kn">as</span> <span class="nn">K</span>
<span class="kn">from</span> <span class="nn">keras.optimizers</span> <span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span> <span class="nn">keras.utils</span> <span class="kn">import</span> <span class="n">to_categorical</span>
<span class="kn">from</span> <span class="nn">keras.losses</span> <span class="kn">import</span> <span class="n">SparseCategoricalCrossentropy</span><span class="p">,</span> <span class="n">binary_crossentropy</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">BertTokenizer</span><span class="p">,</span>
    <span class="n">TFBertForPreTraining</span><span class="p">,</span>
    <span class="n">TFBertModel</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">precision_score</span><span class="p">,</span> <span class="n">recall_score</span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span>
<span class="s">```</span>




    &#39;2.3.0&#39;




<span class="s">```python
</span><span class="s"></span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span><span class="n">data_path</span> <span class="o">=</span> <span class="s2">&#34;sohu2021_open_data_clean/&#34;</span>
<span class="n">text_max_length</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">bert_path</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&#34;../chinese_L-12_H-768_A-12&#34;</span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span>
<span class="s">```</span>

<span class="gh"># 构建标签表
</span><span class="gh"></span>

<span class="s">```python
</span><span class="s"></span><span class="n">label_to_id</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;0&#39;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;1&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">}</span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span><span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span>
<span class="s">```</span>

<span class="gh"># 构建原数据文本迭代器
</span><span class="gh"></span>

<span class="s">```python
</span><span class="s"></span><span class="k">def</span> <span class="nf">_transform_text</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
   <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="s1">&#39;。&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\u3000</span><span class="s1">&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span>
   <span class="k">return</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;。+&#39;</span><span class="p">,</span> <span class="s1">&#39;。&#39;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span><span class="k">def</span> <span class="nf">get_data_iterator</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="n">file_name</span><span class="p">):</span>
    <span class="c1"># TODO: 随机取</span>
    <span class="k">for</span> <span class="n">category</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">data_path</span><span class="p">):</span>
        <span class="n">category_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="n">category</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="n">category_path</span><span class="p">):</span>
            <span class="k">continue</span>
            
        <span class="n">file_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">category_path</span><span class="p">,</span> <span class="n">file_name</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">file_path</span><span class="p">):</span>
            <span class="k">continue</span>
        
<span class="c1">#         print(file_path)</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>
                <span class="n">data</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
                
                <span class="n">data</span><span class="p">[</span><span class="s1">&#39;source&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_transform_text</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;source&#39;</span><span class="p">])</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;source&#39;</span><span class="p">])</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;source:&#39;</span><span class="p">,</span> <span class="n">line</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
                    <span class="k">break</span>
<span class="c1">#                     continue</span>
                    
                <span class="n">data</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_transform_text</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">])</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">])</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;target:&#39;</span><span class="p">,</span> <span class="n">line</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
                    <span class="k">break</span>
<span class="c1">#                     continue</span>
                
                <span class="n">label_name_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">key</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">if</span> <span class="n">key</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;label&#39;</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">label_name_list</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;label_name_list:&#39;</span><span class="p">,</span> <span class="n">line</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
                    <span class="k">break</span>
<span class="c1">#                     continue</span>
                <span class="n">label_name</span> <span class="o">=</span> <span class="n">label_name_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">data</span><span class="p">[</span><span class="n">label_name</span><span class="p">]</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">label_to_id</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;label_name:&#39;</span><span class="p">,</span> <span class="n">line</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">label_name</span><span class="p">)</span>
                    <span class="k">break</span>
<span class="c1">#                     continue</span>
                    
                <span class="k">yield</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;source&#39;</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">],</span> <span class="n">label_to_id</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="n">label_name</span><span class="p">]]</span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span><span class="n">it</span> <span class="o">=</span> <span class="n">get_data_iterator</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="s2">&#34;train.txt&#34;</span><span class="p">)</span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span><span class="nb">next</span><span class="p">(</span><span class="n">it</span><span class="p">)</span>
<span class="s">```</span>




    (&#39;谁能打破科比81分纪录？奥尼尔给出5个候选人，补充利拉德比尔！&#39;, &#39;NBA现役能入名人堂的球星很多，但是能被立铜像只有2人&#39;, 0)




<span class="s">```python
</span><span class="s"></span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span>
<span class="s">```</span>

<span class="gh"># 获取数据集样本个数
</span><span class="gh"></span>

<span class="s">```python
</span><span class="s"></span><span class="k">def</span> <span class="nf">get_sample_num</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="n">file_name</span><span class="p">):</span>
    <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">it</span> <span class="o">=</span> <span class="n">get_data_iterator</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="n">file_name</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">it</span><span class="p">):</span>
        <span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">count</span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span><span class="n">train_sample_count</span> <span class="o">=</span> <span class="n">get_sample_num</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="s2">&#34;train.txt&#34;</span><span class="p">)</span>
<span class="s">```</span>

    59638it [00:04, 13354.07it/s]



<span class="s">```python
</span><span class="s"></span><span class="n">dev_sample_count</span> <span class="o">=</span> <span class="n">get_sample_num</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="s2">&#34;valid.txt&#34;</span><span class="p">)</span>
<span class="s">```</span>

    9940it [00:00, 13041.43it/s]



<span class="s">```python
</span><span class="s"></span><span class="n">train_sample_count</span><span class="p">,</span> <span class="n">dev_sample_count</span>
<span class="s">```</span>




    (59638, 9940)




<span class="s">```python
</span><span class="s"></span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span>
<span class="s">```</span>

<span class="gh"># 构建数据迭代器
</span><span class="gh"></span>

<span class="s">```python
</span><span class="s"></span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">BertTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">bert_path</span><span class="p">)</span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span><span class="k">def</span> <span class="nf">_get_indices</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">text_pair</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">,</span>
                            <span class="n">text_pair</span><span class="o">=</span><span class="n">text_pair</span><span class="p">,</span>
                            <span class="n">max_length</span><span class="o">=</span><span class="n">text_max_length</span><span class="p">,</span> 
                            <span class="n">add_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
                            <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;max_length&#39;</span><span class="p">,</span> 
                            <span class="n">truncation_strategy</span><span class="o">=</span><span class="s1">&#39;only_first&#39;</span><span class="p">,</span> 
<span class="c1">#                                          return_tensors=&#39;tf&#39;</span>
                            <span class="p">)</span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span><span class="k">def</span> <span class="nf">get_keras_bert_iterator</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="n">file_name</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">):</span>
    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
        <span class="n">data_it</span> <span class="o">=</span> <span class="n">get_data_iterator</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="n">file_name</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">source</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">data_it</span><span class="p">:</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">_get_indices</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">source</span><span class="p">,</span> 
                                   <span class="n">text_pair</span><span class="o">=</span><span class="n">target</span><span class="p">)</span>
            <span class="k">yield</span> <span class="n">indices</span><span class="p">,</span> <span class="n">label</span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span><span class="n">it</span> <span class="o">=</span> <span class="n">get_keras_bert_iterator</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="s2">&#34;train.txt&#34;</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">)</span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span><span class="c1"># next(it)</span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span>
<span class="s">```</span>

<span class="gh"># 构建批次数据迭代器
</span><span class="gh"></span>

<span class="s">```python
</span><span class="s"></span><span class="k">def</span> <span class="nf">batch_iter</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="n">file_name</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="s2">&#34;&#34;&#34;生成批次数据&#34;&#34;&#34;</span>
    <span class="n">keras_bert_iter</span> <span class="o">=</span> <span class="n">get_keras_bert_iterator</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="n">file_name</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">)</span>
    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
        <span class="n">data_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
            <span class="n">data</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">keras_bert_iter</span><span class="p">)</span>
            <span class="n">data_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">shuffle</span><span class="p">:</span>
            <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">data_list</span><span class="p">)</span>
        
        <span class="n">indices_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">label_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">data_list</span><span class="p">:</span>
            <span class="n">indices</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">data</span>
            <span class="n">indices_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
            <span class="n">label_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>

        <span class="k">yield</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">indices_list</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">label_list</span><span class="p">)</span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span><span class="n">it</span> <span class="o">=</span> <span class="n">batch_iter</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="s2">&#34;train.txt&#34;</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span><span class="c1"># next(it)</span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span><span class="n">it</span> <span class="o">=</span> <span class="n">batch_iter</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="s2">&#34;train.txt&#34;</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span><span class="nb">next</span><span class="p">(</span><span class="n">it</span><span class="p">)</span>
<span class="s">```</span>

    /home/zsd-server/miniconda3/envs/my/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2162: FutureWarning: The <span class="sb">`truncation_strategy`</span> argument is deprecated and will be removed in a future version, use <span class="sb">`truncation=True`</span> to truncate examples to a max length. You can give a specific length with <span class="sb">`max_length`</span> (e.g. <span class="sb">`max_length=45`</span>) or leave max_length to None to truncate to the maximal input size of the model (e.g. 512 for Bert).  If you have pairs of inputs, you can give a specific truncation strategy selected among <span class="sb">`truncation=&#39;only_first&#39;`</span> (will only truncate the first sentence in the pairs) <span class="sb">`truncation=&#39;only_second&#39;`</span> (will only truncate the second sentence in the pairs) or <span class="sb">`truncation=&#39;longest_first&#39;`</span> (will iteratively remove tokens from the longest sentence in the pairs).
      warnings.warn(





    (array([[ 101, 6435, 2810, ...,    0,    0,    0],
            [ 101, 6443, 5543, ...,    0,    0,    0]]),
     array([0, 0]))




<span class="s">```python
</span><span class="s"></span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span>
<span class="s">```</span>

<span class="gh"># 定义base模型
</span><span class="gh"></span>

<span class="s">```python
</span><span class="s"></span><span class="c1"># !transformers-cli convert --model_type bert \</span>
<span class="c1">#   --tf_checkpoint chinese_L-12_H-768_A-12/bert_model.ckpt \</span>
<span class="c1">#   --config chinese_L-12_H-768_A-12/bert_config.json \</span>
<span class="c1">#   --pytorch_dump_output chinese_L-12_H-768_A-12/pytorch_model.bin</span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span><span class="c1"># bert_model = TFBertForPreTraining.from_pretrained(&#34;./chinese_L-12_H-768_A-12/&#34;, from_pt=True)</span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span><span class="c1"># # it = get_keras_bert_iterator(r&#34;data/keras_bert_train.txt&#34;, cat_to_id, tokenizer)</span>
<span class="c1"># it = batch_iter(r&#34;data/keras_bert_train.txt&#34;, cat_to_id, tokenizer, batch_size=1)</span>
<span class="c1"># out = bert_model(next(it)[0])</span>
<span class="c1"># out[0]</span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span><span class="k">def</span> <span class="nf">get_model</span><span class="p">(</span><span class="n">label_list</span><span class="p">):</span>
    <span class="n">K</span><span class="o">.</span><span class="n">clear_session</span><span class="p">()</span>
    
    <span class="n">bert_model</span> <span class="o">=</span> <span class="n">TFBertForPreTraining</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">bert_path</span><span class="p">,</span> <span class="n">from_pt</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
 
    <span class="n">input_indices</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;int32&#39;</span><span class="p">)</span>
 
    <span class="n">bert_output</span> <span class="o">=</span> <span class="n">bert_model</span><span class="p">(</span><span class="n">input_indices</span><span class="p">)</span>
    <span class="n">projection_logits</span> <span class="o">=</span> <span class="n">bert_output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">bert_cls</span> <span class="o">=</span> <span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])(</span><span class="n">projection_logits</span><span class="p">)</span> <span class="c1"># 取出[CLS]对应的向量用来做分类</span>
    
    <span class="n">dropout</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)(</span><span class="n">bert_cls</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">label_list</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">)(</span><span class="n">dropout</span><span class="p">)</span>
 
    <span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">input_indices</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;sparse_categorical_crossentropy&#39;</span><span class="p">,</span>
                  <span class="n">optimizer</span><span class="o">=</span><span class="n">Adam</span><span class="p">(</span><span class="mf">1e-5</span><span class="p">),</span>    <span class="c1">#用足够小的学习率</span>
                  <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
    <span class="k">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">model</span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span><span class="n">early_stopping</span> <span class="o">=</span> <span class="n">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>   <span class="c1">#早停法，防止过拟合</span>
<span class="n">plateau</span> <span class="o">=</span> <span class="n">ReduceLROnPlateau</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s2">&#34;val_accuracy&#34;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;max&#39;</span><span class="p">,</span> <span class="n">factor</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="c1">#当评价指标不在提升时，减少学习率</span>
<span class="n">checkpoint</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="s1">&#39;trained_model/keras_bert_sohu.hdf5&#39;</span><span class="p">,</span> <span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span><span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">save_best_only</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;max&#39;</span><span class="p">,</span> <span class="n">save_weights_only</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="c1">#保存最好的模型</span>
<span class="s">```</span>

<span class="gu">## 模型训练
</span><span class="gu"></span>

<span class="s">```python
</span><span class="s"></span><span class="k">def</span> <span class="nf">get_step</span><span class="p">(</span><span class="n">sample_count</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="n">step</span> <span class="o">=</span> <span class="n">sample_count</span> <span class="o">//</span> <span class="n">batch_size</span>
    <span class="k">if</span> <span class="n">sample_count</span> <span class="o">%</span> <span class="n">batch_size</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">step</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">step</span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span><span class="c1"># batch_size = 2</span>
<span class="c1"># train_step = get_step(train_sample_count, batch_size)</span>
<span class="c1"># dev_step = get_step(dev_sample_count, batch_size)</span>

<span class="c1"># train_dataset_iterator = batch_iter(data_path, &#34;train.txt&#34;, tokenizer, batch_size)</span>
<span class="c1"># dev_dataset_iterator = batch_iter(data_path, &#34;valid.txt&#34;, tokenizer, batch_size)</span>

<span class="c1"># model = get_model(labels)</span>

<span class="c1"># #模型训练</span>
<span class="c1"># model.fit(</span>
<span class="c1">#     train_dataset_iterator,</span>
<span class="c1">#     steps_per_epoch=10,</span>
<span class="c1"># #     steps_per_epoch=train_step,</span>
<span class="c1">#     epochs=5,</span>
<span class="c1">#     validation_data=dev_dataset_iterator,</span>
<span class="c1">#     validation_steps=2,</span>
<span class="c1"># #     validation_steps=dev_step,</span>
<span class="c1">#     callbacks=[early_stopping, plateau, checkpoint],</span>
<span class="c1">#     verbose=1</span>
<span class="c1"># )</span>

<span class="c1"># model.save_weights(&#34;trained_model/keras_bert_sohu_final.weights&#34;)</span>
<span class="c1"># model.save(&#34;trained_model/keras_bert_sohu_final.model&#34;)</span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span>
<span class="s">```</span>

<span class="gh"># 多任务分支模型
</span><span class="gh"></span>
<span class="gu">## 构建数据迭代器
</span><span class="gu"></span>

<span class="s">```python
</span><span class="s"></span><span class="n">label_type_to_id</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;labelA&#39;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;labelB&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">}</span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span><span class="k">def</span> <span class="nf">get_text_iterator</span><span class="p">(</span><span class="n">file_path</span><span class="p">):</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">line</span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span><span class="k">def</span> <span class="nf">get_data_iterator</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="n">file_name</span><span class="p">):</span>
    <span class="c1"># TODO: 随机取</span>
    <span class="n">file_iters</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">category</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">data_path</span><span class="p">):</span>
        <span class="n">category_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="n">category</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="n">category_path</span><span class="p">):</span>
            <span class="k">continue</span>
            
        <span class="n">file_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">category_path</span><span class="p">,</span> <span class="n">file_name</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">file_path</span><span class="p">):</span>
            <span class="k">continue</span>
            
        
        <span class="n">file_iter</span> <span class="o">=</span> <span class="n">get_text_iterator</span><span class="p">(</span><span class="n">file_path</span><span class="p">)</span>
        <span class="n">file_iters</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">file_iter</span><span class="p">)</span>
        
    <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">file_iters</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">i</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randrange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">file_iters</span><span class="p">))</span>
        <span class="n">line</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">file_iters</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="bp">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">line</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="k">del</span> <span class="n">file_iters</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="k">continue</span>
            
        <span class="n">data</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>

        <span class="n">data</span><span class="p">[</span><span class="s1">&#39;source&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_transform_text</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;source&#39;</span><span class="p">])</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;source&#39;</span><span class="p">])</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s1">&#39;source:&#39;</span><span class="p">,</span> <span class="n">line</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
            <span class="k">break</span>
<span class="c1">#                     continue</span>

        <span class="n">data</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_transform_text</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">])</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">])</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s1">&#39;target:&#39;</span><span class="p">,</span> <span class="n">line</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
            <span class="k">break</span>
<span class="c1">#                     continue</span>

        <span class="n">label_name_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">key</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">if</span> <span class="n">key</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;label&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">label_name_list</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s1">&#39;label_name_list:&#39;</span><span class="p">,</span> <span class="n">line</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
            <span class="k">break</span>
<span class="c1">#                     continue</span>
        <span class="n">label_name</span> <span class="o">=</span> <span class="n">label_name_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">data</span><span class="p">[</span><span class="n">label_name</span><span class="p">]</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">label_to_id</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="k">print</span><span class="p">(</span><span class="s1">&#39;label_name:&#39;</span><span class="p">,</span> <span class="n">line</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">label_name</span><span class="p">)</span>
            <span class="k">break</span>
<span class="c1">#                     continue</span>
        
        <span class="n">label_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">label_type_to_id</span><span class="o">.</span><span class="n">keys</span><span class="p">()}</span>
        <span class="n">label_dict</span><span class="p">[</span><span class="n">label_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">label_to_id</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="n">label_name</span><span class="p">]]</span>
        <span class="k">if</span> <span class="n">label_dict</span><span class="p">[</span><span class="s1">&#39;labelA&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">label_dict</span><span class="p">[</span><span class="s1">&#39;labelB&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">if</span> <span class="n">label_dict</span><span class="p">[</span><span class="s1">&#39;labelB&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">label_dict</span><span class="p">[</span><span class="s1">&#39;labelA&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="k">yield</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;source&#39;</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">],</span> <span class="n">label_dict</span><span class="p">[</span><span class="s1">&#39;labelA&#39;</span><span class="p">],</span> <span class="n">label_dict</span><span class="p">[</span><span class="s1">&#39;labelB&#39;</span><span class="p">]</span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span><span class="n">it</span> <span class="o">=</span> <span class="n">get_data_iterator</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="s2">&#34;train.txt&#34;</span><span class="p">)</span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span><span class="nb">next</span><span class="p">(</span><span class="n">it</span><span class="p">)</span>
<span class="s">```</span>




    (&#39;谁能打破科比81分纪录？奥尼尔给出5个候选人，补充利拉德比尔！&#39;, &#39;NBA现役能入名人堂的球星很多，但是能被立铜像只有2人&#39;, 0, 0)




<span class="s">```python
</span><span class="s"></span><span class="n">get_sample_num</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="s2">&#34;train.txt&#34;</span><span class="p">)</span>
<span class="s">```</span>

    59638it [00:04, 11996.58it/s]





    59638




<span class="s">```python
</span><span class="s"></span><span class="k">def</span> <span class="nf">_get_indices</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">text_pair</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode_plus</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">,</span>
                            <span class="n">text_pair</span><span class="o">=</span><span class="n">text_pair</span><span class="p">,</span>
                            <span class="n">max_length</span><span class="o">=</span><span class="n">text_max_length</span><span class="p">,</span> 
                            <span class="n">add_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
                            <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;max_length&#39;</span><span class="p">,</span> 
                            <span class="n">truncation_strategy</span><span class="o">=</span><span class="s1">&#39;longest_first&#39;</span><span class="p">,</span> 
<span class="c1">#                                          return_tensors=&#39;tf&#39;,</span>
                            <span class="n">return_token_type_ids</span><span class="o">=</span><span class="bp">True</span>
                            <span class="p">)</span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span><span class="k">def</span> <span class="nf">get_keras_bert_iterator</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="n">file_name</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">):</span>
    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
        <span class="n">data_it</span> <span class="o">=</span> <span class="n">get_data_iterator</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="n">file_name</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">source</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">labelA</span><span class="p">,</span> <span class="n">labelB</span> <span class="ow">in</span> <span class="n">data_it</span><span class="p">:</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">_get_indices</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">source</span><span class="p">,</span> 
                                   <span class="n">text_pair</span><span class="o">=</span><span class="n">target</span><span class="p">)</span>
<span class="c1">#             print(indices, type(indices), len(indices))</span>
            <span class="k">yield</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;token_type_ids&#39;</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">],</span> <span class="n">labelA</span><span class="p">,</span> <span class="n">labelB</span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span><span class="n">it</span> <span class="o">=</span> <span class="n">get_keras_bert_iterator</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="s2">&#34;train.txt&#34;</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">)</span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span><span class="c1"># next(it)</span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span><span class="k">def</span> <span class="nf">batch_iter</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="n">file_name</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="s2">&#34;&#34;&#34;生成批次数据&#34;&#34;&#34;</span>
    <span class="n">keras_bert_iter</span> <span class="o">=</span> <span class="n">get_keras_bert_iterator</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="n">file_name</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">)</span>
    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
        <span class="n">data_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
            <span class="n">data</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">keras_bert_iter</span><span class="p">)</span>
            <span class="n">data_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">shuffle</span><span class="p">:</span>
            <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">data_list</span><span class="p">)</span>
        
        <span class="n">input_ids_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">token_type_ids_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">attention_mask_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">labelA_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">labelB_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">data_list</span><span class="p">:</span>
            <span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">labelA</span><span class="p">,</span> <span class="n">labelB</span> <span class="o">=</span> <span class="n">data</span>
<span class="c1">#             print(indices, type(indices))</span>
            <span class="n">input_ids_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
            <span class="n">token_type_ids_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">token_type_ids</span><span class="p">)</span>
            <span class="n">attention_mask_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">attention_mask</span><span class="p">)</span>
            <span class="n">labelA_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">labelA</span><span class="p">)</span>
            <span class="n">labelB_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">labelB</span><span class="p">)</span>

        <span class="k">yield</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">input_ids_list</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">token_type_ids_list</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">attention_mask_list</span><span class="p">)],</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">labelA_list</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">labelB_list</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)]</span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span><span class="n">it</span> <span class="o">=</span> <span class="n">batch_iter</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="s2">&#34;train.txt&#34;</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span><span class="nb">next</span><span class="p">(</span><span class="n">it</span><span class="p">)</span>
<span class="s">```</span>




    ([array([[ 101, 5381, 5273, ...,    0,    0,    0],
             [ 101, 3297, 6818, ..., 8024, 4125,  102]]),
      array([[0, 0, 0, ..., 0, 0, 0],
             [0, 0, 0, ..., 1, 1, 1]]),
      array([[1, 1, 1, ..., 0, 0, 0],
             [1, 1, 1, ..., 1, 1, 1]])],
     [array([-1,  1], dtype=int32), array([ 0, -1], dtype=int32)])



<span class="gu">## 定义模型
</span><span class="gu"></span>

<span class="s">```python
</span><span class="s"></span><span class="k">def</span> <span class="nf">transform_y</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="n">mask_value</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">mask_y_true</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">not_equal</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">mask_value</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span>
<span class="c1">#     print(f&#34;mask_y_true:{mask_y_true}&#34;)</span>
<span class="c1">#     y_true_ = tf.cond(tf.equal(y_true, mask_value), lambda: 0, lambda: y_true)</span>
    <span class="n">y_true_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">mask_y_true</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">y_pred_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">mask_y_true</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="c1">#     print(f&#34;y_true_:{y_true_}, y_pred_:{y_pred_}&#34;)</span>
    
    <span class="k">return</span> <span class="n">y_true_</span><span class="p">,</span> <span class="n">y_pred_</span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span><span class="k">def</span> <span class="nf">my_binary_crossentropy</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
<span class="c1">#     print(f&#34;y_true:{y_true}, y_pred:{y_pred}&#34;)</span>
    
    <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="n">transform_y</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="c1">#     print(f&#34;y_true_:{y_true}, y_pred_:{y_pred}&#34;)</span>

    <span class="n">loss</span> <span class="o">=</span> <span class="n">binary_crossentropy</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="c1">#     print(f&#34;loss:{loss}&#34;)</span>
    <span class="k">return</span> <span class="n">loss</span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span><span class="k">def</span> <span class="nf">tarnsform_metrics</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="n">y_true_</span><span class="p">,</span> <span class="n">y_pred_</span> <span class="o">=</span> <span class="n">y_true</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">y_true_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">y_true_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="k">if</span> <span class="n">y_true_</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
                <span class="n">y_true_</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="n">y_pred_</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">if</span> <span class="n">y_pred_</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">:</span>
                <span class="n">y_pred_</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">y_pred_</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">return</span> <span class="n">y_true_</span><span class="p">,</span> <span class="n">y_pred_</span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span><span class="k">def</span> <span class="nf">my_binary_accuracy</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
<span class="c1">#     print(&#34;my_binary_accuracy&#34;)</span>
<span class="c1">#     print(f&#34;y_true:{y_true}, y_pred:{y_pred}&#34;)</span>
    
    <span class="n">y_true_</span><span class="p">,</span> <span class="n">y_pred_</span> <span class="o">=</span> <span class="n">tarnsform_metrics</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="c1">#     print(f&#34;y_true_:{y_true_}, y_pred_:{y_pred_}&#34;)</span>

    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">binary_accuracy</span><span class="p">(</span><span class="n">y_true_</span><span class="p">,</span> <span class="n">y_pred_</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">accuracy</span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span><span class="k">def</span> <span class="nf">my_f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
<span class="c1">#     print(&#34;my_f1_score&#34;)</span>
<span class="c1">#     print(f&#34;y_true:{y_true}, y_pred:{y_pred}&#34;)</span>
    
    <span class="n">y_true_</span><span class="p">,</span> <span class="n">y_pred_</span> <span class="o">=</span> <span class="n">tarnsform_metrics</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="c1">#     print(f&#34;y_true_:{y_true_}, y_pred_:{y_pred_}&#34;)</span>

    <span class="k">return</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_true_</span><span class="p">,</span> <span class="n">y_pred_</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">)</span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span><span class="k">def</span> <span class="nf">get_model</span><span class="p">():</span>
    <span class="n">K</span><span class="o">.</span><span class="n">clear_session</span><span class="p">()</span>
    
    <span class="n">bert_model</span> <span class="o">=</span> <span class="n">TFBertForPreTraining</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">bert_path</span><span class="p">,</span> <span class="n">from_pt</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
 
    <span class="n">input_ids</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;int32&#39;</span><span class="p">)</span>
    <span class="n">input_token_type_ids</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;int32&#39;</span><span class="p">)</span>
    <span class="n">input_attention_mask</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;int32&#39;</span><span class="p">)</span>
 
    <span class="n">bert_output</span> <span class="o">=</span> <span class="n">bert_model</span><span class="p">({</span><span class="s1">&#39;input_ids&#39;</span><span class="p">:</span><span class="n">input_ids</span><span class="p">,</span> <span class="s1">&#39;token_type_ids&#39;</span><span class="p">:</span><span class="n">input_token_type_ids</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">:</span><span class="n">input_attention_mask</span><span class="p">},</span> <span class="n">return_dict</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">projection_logits</span> <span class="o">=</span> <span class="n">bert_output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">bert_cls</span> <span class="o">=</span> <span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])(</span><span class="n">projection_logits</span><span class="p">)</span> <span class="c1"># 取出[CLS]对应的向量用来做分类</span>
    
    <span class="n">dropout_A</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)(</span><span class="n">bert_cls</span><span class="p">)</span>
    <span class="n">output_A</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">)(</span><span class="n">dropout_A</span><span class="p">)</span>
    
    <span class="n">dropout_B</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)(</span><span class="n">bert_cls</span><span class="p">)</span>
    <span class="n">output_B</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">)(</span><span class="n">dropout_B</span><span class="p">)</span>
 
    <span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">([</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">input_token_type_ids</span><span class="p">,</span> <span class="n">input_attention_mask</span><span class="p">],</span> <span class="p">[</span><span class="n">output_A</span><span class="p">,</span> <span class="n">output_B</span><span class="p">])</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
                  <span class="n">loss</span><span class="o">=</span><span class="n">my_binary_crossentropy</span><span class="p">,</span>
<span class="c1">#                   loss=&#39;binary_crossentropy&#39;,</span>
<span class="c1">#                   loss=binary_crossentropy,</span>
                  <span class="n">optimizer</span><span class="o">=</span><span class="n">Adam</span><span class="p">(</span><span class="mf">1e-5</span><span class="p">),</span>    <span class="c1">#用足够小的学习率</span>
                  <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">my_binary_accuracy</span><span class="p">,</span> <span class="n">my_f1_score</span><span class="p">]</span>
<span class="c1">#                   metrics=&#39;accuracy&#39;</span>
                 <span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">model</span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span><span class="n">early_stopping</span> <span class="o">=</span> <span class="n">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>   <span class="c1">#早停法，防止过拟合</span>
<span class="n">plateau</span> <span class="o">=</span> <span class="n">ReduceLROnPlateau</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s2">&#34;val_loss&#34;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;max&#39;</span><span class="p">,</span> <span class="n">factor</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="c1">#当评价指标不在提升时，减少学习率</span>
<span class="n">checkpoint</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="s1">&#39;trained_model/multi_keras_bert_sohu.hdf5&#39;</span><span class="p">,</span> <span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span><span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">save_best_only</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;max&#39;</span><span class="p">,</span> <span class="n">save_weights_only</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="c1">#保存最好的模型</span>
<span class="s">```</span>

<span class="gu">## 模型训练
</span><span class="gu"></span>

<span class="s">```python
</span><span class="s"></span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">train_step</span> <span class="o">=</span> <span class="n">get_step</span><span class="p">(</span><span class="n">train_sample_count</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
<span class="n">dev_step</span> <span class="o">=</span> <span class="n">get_step</span><span class="p">(</span><span class="n">dev_sample_count</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>

<span class="n">train_dataset_iterator</span> <span class="o">=</span> <span class="n">batch_iter</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="s2">&#34;train.txt&#34;</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
<span class="n">dev_dataset_iterator</span> <span class="o">=</span> <span class="n">batch_iter</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="s2">&#34;valid.txt&#34;</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">get_model</span><span class="p">()</span>

<span class="c1">#模型训练</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">train_dataset_iterator</span><span class="p">,</span>
    <span class="n">steps_per_epoch</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="c1">#     steps_per_epoch=train_step,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="n">dev_dataset_iterator</span><span class="p">,</span>
    <span class="n">validation_steps</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="c1">#     validation_steps=dev_step,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">early_stopping</span><span class="p">,</span> <span class="n">plateau</span><span class="p">,</span> <span class="n">checkpoint</span><span class="p">],</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span>
<span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">save_weights</span><span class="p">(</span><span class="s2">&#34;trained_model/multi_keras_bert_sohu_final.weights&#34;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&#34;trained_model/multi_keras_bert_sohu_final.model&#34;</span><span class="p">)</span>
<span class="s">```</span>

    Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForPreTraining: [&#39;bert.embeddings.position_ids&#39;, &#39;cls.predictions.decoder.bias&#39;]
    <span class="k">-</span> This IS expected if you are initializing TFBertForPreTraining from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).
    <span class="k">-</span> This IS NOT expected if you are initializing TFBertForPreTraining from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).
    All the weights of TFBertForPreTraining were initialized from the PyTorch model.
    If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForPreTraining for predictions without further training.


    WARNING: AutoGraph could not transform &lt;bound method Socket.send of &lt;zmq.sugar.socket.Socket object at 0x7f74107b3460&gt;&gt; and will run it as-is.
    Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, <span class="sb">`export AUTOGRAPH_VERBOSITY=10`</span>) and attach the full output.
    Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method
    To silence this warning, decorate the function with <span class="ni">@tf</span>.autograph.experimental.do_not_convert


    The parameter <span class="sb">`return_dict`</span> cannot be set in graph mode and will always be set to <span class="sb">`True`</span>.
    The parameters <span class="sb">`output_attentions`</span>, <span class="sb">`output_hidden_states`</span> and <span class="sb">`use_cache`</span> cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: <span class="sb">`config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`</span>).
    The parameter <span class="sb">`return_dict`</span> cannot be set in graph mode and will always be set to <span class="sb">`True`</span>.


    Model: &#34;functional_1&#34;
    <span class="gs">__________________________________________________________________________________________________</span>
    Layer (type)                    Output Shape         Param #     Connected to                     
    ==================================================================================================
    input_3 (InputLayer)            [(None, None)]       0                                            
    <span class="gs">__________________________________________________________________________________________________</span>
    input_1 (InputLayer)            [(None, None)]       0                                            
    <span class="gs">__________________________________________________________________________________________________</span>
    input_2 (InputLayer)            [(None, None)]       0                                            
    <span class="gs">__________________________________________________________________________________________________</span>
    tf_bert_for_pre_training (TFBer TFBertForPreTraining 102882442   input_3[0][0]                    
                                                                     input_1[0][0]                    
                                                                     input_2[0][0]                    
    <span class="gs">__________________________________________________________________________________________________</span>
    lambda (Lambda)                 (None, 21128)        0           tf_bert_for_pre_training[0][0]   
    <span class="gs">__________________________________________________________________________________________________</span>
    dropout_37 (Dropout)            (None, 21128)        0           lambda[0][0]                     
    <span class="gs">__________________________________________________________________________________________________</span>
    dropout_38 (Dropout)            (None, 21128)        0           lambda[0][0]                     
    <span class="gs">__________________________________________________________________________________________________</span>
    dense (Dense)                   (None, 1)            21129       dropout_37[0][0]                 
    <span class="gs">__________________________________________________________________________________________________</span>
    dense_1 (Dense)                 (None, 1)            21129       dropout_38[0][0]                 
    ==================================================================================================
    Total params: 102,924,700
    Trainable params: 102,924,700
    Non-trainable params: 0
    <span class="gs">__________________________________________________________________________________________________</span>
    None
    Epoch 1/2


    /home/zsd-server/miniconda3/envs/my/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2162: FutureWarning: The <span class="sb">`truncation_strategy`</span> argument is deprecated and will be removed in a future version, use <span class="sb">`truncation=True`</span> to truncate examples to a max length. You can give a specific length with <span class="sb">`max_length`</span> (e.g. <span class="sb">`max_length=45`</span>) or leave max_length to None to truncate to the maximal input size of the model (e.g. 512 for Bert).  If you have pairs of inputs, you can give a specific truncation strategy selected among <span class="sb">`truncation=&#39;only_first&#39;`</span> (will only truncate the first sentence in the pairs) <span class="sb">`truncation=&#39;only_second&#39;`</span> (will only truncate the second sentence in the pairs) or <span class="sb">`truncation=&#39;longest_first&#39;`</span> (will iteratively remove tokens from the longest sentence in the pairs).
      warnings.warn(
    /home/zsd-server/miniconda3/envs/my/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:3349: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.
      warnings.warn(


    10/10 [==============================] - ETA: 0s - loss: 2.9102 - dense_loss: 0.7665 - dense_1_loss: 2.1437 - dense_my_binary_accuracy: 0.8500 - dense_my_f1_score: 0.8000 - dense_1_my_binary_accuracy: 0.6500 - dense_1_my_f1_score: 0.5667
    Epoch 00001: val_loss improved from -inf to 1.98809, saving model to trained_model/multi_keras_bert_sohu.hdf5
    10/10 [==============================] - 111s 11s/step - loss: 2.9102 - dense_loss: 0.7665 - dense_1_loss: 2.1437 - dense_my_binary_accuracy: 0.8500 - dense_my_f1_score: 0.8000 - dense_1_my_binary_accuracy: 0.6500 - dense_1_my_f1_score: 0.5667 - val_loss: 1.9881 - val_dense_loss: 1.9870 - val_dense_1_loss: 0.0011 - val_dense_my_binary_accuracy: 0.7500 - val_dense_my_f1_score: 0.6667 - val_dense_1_my_binary_accuracy: 1.0000 - val_dense_1_my_f1_score: 1.0000
    Epoch 2/2
    10/10 [==============================] - ETA: 0s - loss: 3.0176 - dense_loss: 2.8052 - dense_1_loss: 0.2125 - dense_my_binary_accuracy: 0.7500 - dense_my_f1_score: 0.7000 - dense_1_my_binary_accuracy: 0.9000 - dense_1_my_f1_score: 0.8667 
    Epoch 00002: val_loss improved from 1.98809 to 2.56778, saving model to trained_model/multi_keras_bert_sohu.hdf5
    10/10 [==============================] - 114s 11s/step - loss: 3.0176 - dense_loss: 2.8052 - dense_1_loss: 0.2125 - dense_my_binary_accuracy: 0.7500 - dense_my_f1_score: 0.7000 - dense_1_my_binary_accuracy: 0.9000 - dense_1_my_f1_score: 0.8667 - val_loss: 2.5678 - val_dense_loss: 2.5678 - val_dense_1_loss: 7.7785e-06 - val_dense_my_binary_accuracy: 0.5000 - val_dense_my_f1_score: 0.3333 - val_dense_1_my_binary_accuracy: 1.0000 - val_dense_1_my_f1_score: 1.0000


    The parameter <span class="sb">`return_dict`</span> cannot be set in graph mode and will always be set to <span class="sb">`True`</span>.
    The parameters <span class="sb">`output_attentions`</span>, <span class="sb">`output_hidden_states`</span> and <span class="sb">`use_cache`</span> cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: <span class="sb">`config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`</span>).
    The parameter <span class="sb">`return_dict`</span> cannot be set in graph mode and will always be set to <span class="sb">`True`</span>.
    The parameters <span class="sb">`output_attentions`</span>, <span class="sb">`output_hidden_states`</span> and <span class="sb">`use_cache`</span> cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: <span class="sb">`config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`</span>).
    The parameter <span class="sb">`return_dict`</span> cannot be set in graph mode and will always be set to <span class="sb">`True`</span>.
    The parameters <span class="sb">`output_attentions`</span>, <span class="sb">`output_hidden_states`</span> and <span class="sb">`use_cache`</span> cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: <span class="sb">`config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`</span>).
    The parameter <span class="sb">`return_dict`</span> cannot be set in graph mode and will always be set to <span class="sb">`True`</span>.
    The parameters <span class="sb">`output_attentions`</span>, <span class="sb">`output_hidden_states`</span> and <span class="sb">`use_cache`</span> cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: <span class="sb">`config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`</span>).
    The parameter <span class="sb">`return_dict`</span> cannot be set in graph mode and will always be set to <span class="sb">`True`</span>.
    The parameters <span class="sb">`output_attentions`</span>, <span class="sb">`output_hidden_states`</span> and <span class="sb">`use_cache`</span> cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: <span class="sb">`config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`</span>).
    The parameter <span class="sb">`return_dict`</span> cannot be set in graph mode and will always be set to <span class="sb">`True`</span>.
    The parameters <span class="sb">`output_attentions`</span>, <span class="sb">`output_hidden_states`</span> and <span class="sb">`use_cache`</span> cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: <span class="sb">`config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`</span>).
    The parameter <span class="sb">`return_dict`</span> cannot be set in graph mode and will always be set to <span class="sb">`True`</span>.
    The parameters <span class="sb">`output_attentions`</span>, <span class="sb">`output_hidden_states`</span> and <span class="sb">`use_cache`</span> cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: <span class="sb">`config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`</span>).
    The parameter <span class="sb">`return_dict`</span> cannot be set in graph mode and will always be set to <span class="sb">`True`</span>.
    The parameters <span class="sb">`output_attentions`</span>, <span class="sb">`output_hidden_states`</span> and <span class="sb">`use_cache`</span> cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: <span class="sb">`config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`</span>).
    The parameter <span class="sb">`return_dict`</span> cannot be set in graph mode and will always be set to <span class="sb">`True`</span>.
    The parameters <span class="sb">`output_attentions`</span>, <span class="sb">`output_hidden_states`</span> and <span class="sb">`use_cache`</span> cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: <span class="sb">`config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`</span>).
    The parameter <span class="sb">`return_dict`</span> cannot be set in graph mode and will always be set to <span class="sb">`True`</span>.
    The parameter <span class="sb">`return_dict`</span> cannot be set in graph mode and will always be set to <span class="sb">`True`</span>.
    The parameters <span class="sb">`output_attentions`</span>, <span class="sb">`output_hidden_states`</span> and <span class="sb">`use_cache`</span> cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: <span class="sb">`config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`</span>).
    The parameter <span class="sb">`return_dict`</span> cannot be set in graph mode and will always be set to <span class="sb">`True`</span>.
    The parameter <span class="sb">`return_dict`</span> cannot be set in graph mode and will always be set to <span class="sb">`True`</span>.
    The parameters <span class="sb">`output_attentions`</span>, <span class="sb">`output_hidden_states`</span> and <span class="sb">`use_cache`</span> cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: <span class="sb">`config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`</span>).
    The parameter <span class="sb">`return_dict`</span> cannot be set in graph mode and will always be set to <span class="sb">`True`</span>.
    The parameter <span class="sb">`return_dict`</span> cannot be set in graph mode and will always be set to <span class="sb">`True`</span>.
    The parameters <span class="sb">`output_attentions`</span>, <span class="sb">`output_hidden_states`</span> and <span class="sb">`use_cache`</span> cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: <span class="sb">`config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`</span>).
    The parameter <span class="sb">`return_dict`</span> cannot be set in graph mode and will always be set to <span class="sb">`True`</span>.
    The parameter <span class="sb">`return_dict`</span> cannot be set in graph mode and will always be set to <span class="sb">`True`</span>.
    The parameters <span class="sb">`output_attentions`</span>, <span class="sb">`output_hidden_states`</span> and <span class="sb">`use_cache`</span> cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: <span class="sb">`config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`</span>).
    The parameter <span class="sb">`return_dict`</span> cannot be set in graph mode and will always be set to <span class="sb">`True`</span>.
    The parameter <span class="sb">`return_dict`</span> cannot be set in graph mode and will always be set to <span class="sb">`True`</span>.
    The parameters <span class="sb">`output_attentions`</span>, <span class="sb">`output_hidden_states`</span> and <span class="sb">`use_cache`</span> cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: <span class="sb">`config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`</span>).
    The parameter <span class="sb">`return_dict`</span> cannot be set in graph mode and will always be set to <span class="sb">`True`</span>.
    The parameter <span class="sb">`return_dict`</span> cannot be set in graph mode and will always be set to <span class="sb">`True`</span>.
    The parameters <span class="sb">`output_attentions`</span>, <span class="sb">`output_hidden_states`</span> and <span class="sb">`use_cache`</span> cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: <span class="sb">`config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`</span>).
    The parameter <span class="sb">`return_dict`</span> cannot be set in graph mode and will always be set to <span class="sb">`True`</span>.
    The parameter <span class="sb">`return_dict`</span> cannot be set in graph mode and will always be set to <span class="sb">`True`</span>.
    The parameters <span class="sb">`output_attentions`</span>, <span class="sb">`output_hidden_states`</span> and <span class="sb">`use_cache`</span> cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: <span class="sb">`config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`</span>).
    The parameter <span class="sb">`return_dict`</span> cannot be set in graph mode and will always be set to <span class="sb">`True`</span>.
    The parameter <span class="sb">`return_dict`</span> cannot be set in graph mode and will always be set to <span class="sb">`True`</span>.
    The parameters <span class="sb">`output_attentions`</span>, <span class="sb">`output_hidden_states`</span> and <span class="sb">`use_cache`</span> cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: <span class="sb">`config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`</span>).
    The parameter <span class="sb">`return_dict`</span> cannot be set in graph mode and will always be set to <span class="sb">`True`</span>.
    The parameter <span class="sb">`return_dict`</span> cannot be set in graph mode and will always be set to <span class="sb">`True`</span>.
    The parameters <span class="sb">`output_attentions`</span>, <span class="sb">`output_hidden_states`</span> and <span class="sb">`use_cache`</span> cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: <span class="sb">`config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`</span>).
    The parameter <span class="sb">`return_dict`</span> cannot be set in graph mode and will always be set to <span class="sb">`True`</span>.
    The parameter <span class="sb">`return_dict`</span> cannot be set in graph mode and will always be set to <span class="sb">`True`</span>.
    The parameters <span class="sb">`output_attentions`</span>, <span class="sb">`output_hidden_states`</span> and <span class="sb">`use_cache`</span> cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: <span class="sb">`config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`</span>).
    The parameter <span class="sb">`return_dict`</span> cannot be set in graph mode and will always be set to <span class="sb">`True`</span>.
    The parameter <span class="sb">`return_dict`</span> cannot be set in graph mode and will always be set to <span class="sb">`True`</span>.
    The parameters <span class="sb">`output_attentions`</span>, <span class="sb">`output_hidden_states`</span> and <span class="sb">`use_cache`</span> cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: <span class="sb">`config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`</span>).
    The parameter <span class="sb">`return_dict`</span> cannot be set in graph mode and will always be set to <span class="sb">`True`</span>.
    The parameter <span class="sb">`return_dict`</span> cannot be set in graph mode and will always be set to <span class="sb">`True`</span>.
    The parameters <span class="sb">`output_attentions`</span>, <span class="sb">`output_hidden_states`</span> and <span class="sb">`use_cache`</span> cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: <span class="sb">`config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`</span>).
    The parameter <span class="sb">`return_dict`</span> cannot be set in graph mode and will always be set to <span class="sb">`True`</span>.
    The parameters <span class="sb">`output_attentions`</span>, <span class="sb">`output_hidden_states`</span> and <span class="sb">`use_cache`</span> cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: <span class="sb">`config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`</span>).
    The parameter <span class="sb">`return_dict`</span> cannot be set in graph mode and will always be set to <span class="sb">`True`</span>.
    The parameters <span class="sb">`output_attentions`</span>, <span class="sb">`output_hidden_states`</span> and <span class="sb">`use_cache`</span> cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: <span class="sb">`config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`</span>).
    The parameter <span class="sb">`return_dict`</span> cannot be set in graph mode and will always be set to <span class="sb">`True`</span>.
    The parameters <span class="sb">`output_attentions`</span>, <span class="sb">`output_hidden_states`</span> and <span class="sb">`use_cache`</span> cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: <span class="sb">`config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`</span>).
    The parameter <span class="sb">`return_dict`</span> cannot be set in graph mode and will always be set to <span class="sb">`True`</span>.
    The parameters <span class="sb">`output_attentions`</span>, <span class="sb">`output_hidden_states`</span> and <span class="sb">`use_cache`</span> cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: <span class="sb">`config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`</span>).
    The parameter <span class="sb">`return_dict`</span> cannot be set in graph mode and will always be set to <span class="sb">`True`</span>.
    The parameters <span class="sb">`output_attentions`</span>, <span class="sb">`output_hidden_states`</span> and <span class="sb">`use_cache`</span> cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: <span class="sb">`config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`</span>).
    The parameter <span class="sb">`return_dict`</span> cannot be set in graph mode and will always be set to <span class="sb">`True`</span>.
    The parameters <span class="sb">`output_attentions`</span>, <span class="sb">`output_hidden_states`</span> and <span class="sb">`use_cache`</span> cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: <span class="sb">`config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`</span>).
    The parameter <span class="sb">`return_dict`</span> cannot be set in graph mode and will always be set to <span class="sb">`True`</span>.
    The parameters <span class="sb">`output_attentions`</span>, <span class="sb">`output_hidden_states`</span> and <span class="sb">`use_cache`</span> cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: <span class="sb">`config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`</span>).
    The parameter <span class="sb">`return_dict`</span> cannot be set in graph mode and will always be set to <span class="sb">`True`</span>.
    The parameters <span class="sb">`output_attentions`</span>, <span class="sb">`output_hidden_states`</span> and <span class="sb">`use_cache`</span> cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: <span class="sb">`config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`</span>).
    The parameter <span class="sb">`return_dict`</span> cannot be set in graph mode and will always be set to <span class="sb">`True`</span>.
    The parameters <span class="sb">`output_attentions`</span>, <span class="sb">`output_hidden_states`</span> and <span class="sb">`use_cache`</span> cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: <span class="sb">`config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`</span>).
    The parameter <span class="sb">`return_dict`</span> cannot be set in graph mode and will always be set to <span class="sb">`True`</span>.



<span class="s">```python
</span><span class="s"></span><span class="n">dev_dataset_iterator</span> <span class="o">=</span> <span class="n">batch_iter</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="s2">&#34;valid.txt&#34;</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">dev_dataset_iterator</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">data</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="s">```</span>




    ([array([[0.00284165]], dtype=float32),
      array([[3.6964306e-05]], dtype=float32)],
     [array([1], dtype=int32), array([-1], dtype=int32)])




<span class="s">```python
</span><span class="s"></span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span>
<span class="s">```</span>

<span class="gh"># 模型加载及测试
</span><span class="gh"></span>
<span class="gu">## load_weights
</span><span class="gu"></span>
<span class="gu">## load_model
</span><span class="gu"></span>

<span class="s">```python
</span><span class="s"></span>
<span class="s">```</span>


<span class="s">```python
</span><span class="s"></span>
<span class="s">```</span>

</code></pre></td></tr></table>
</div>
</div>
    </div>

    
<div class="post-reward">
  <input type="checkbox" name="reward" id="reward" hidden />
  <label class="reward-button" for="reward">赞赏支持</label>
  <div class="qr-code">
    
    <label class="qr-code-image" for="reward">
        <img class="image" src="/images/money_weixin_20200719212002.png">
        <span>微信打赏</span>
      </label>
    <label class="qr-code-image" for="reward">
        <img class="image" src="/images/alipay_20200801211208.png">
        <span>支付宝打赏</span>
      </label>
  </div>
</div><footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a>
          <a href="/tags/%E8%87%AA%E5%AE%9A%E4%B9%89/">自定义</a>
          <a href="/tags/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/">损失函数</a>
          <a href="/tags/%E5%AD%90%E7%BD%91%E7%BB%9C/">子网络</a>
          <a href="/tags/keras/">keras</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/category_embedding/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">将类别特征通过Embedding层映射并进行拼接</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/multi_output_bert_model_with_transformers/">
            <span class="next-text nav-default">用transformers实现多输出、参数共享的bert模型</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        <div id="gitalk-container"></div>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css" crossorigin="anonymous">
    <script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js" crossorigin="anonymous"></script>
    <script type="text/javascript">
      var gitalk = new Gitalk({
        id: '2021-03-31 01:14:58 \x2b0800 CST',
        title: '用自定义损失函数实现选择启用不同子网络',
        clientID: '5ea75f603117948d8d37',
        clientSecret: '26c617c6bce9a975c2a65a68f1ca2a2cc7dde587',
        repo: 'blog',
        owner: 'zhangsheng377',
        admin: ['zhangsheng377'],
        body: decodeURI(location.href)
      });
      gitalk.render('gitalk-container');
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://github.com/gitalk/gitalk">comments powered by gitalk.</a></noscript>

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="mailto:435878393@qq.com" class="iconfont icon-email" title="email"></a>
      <a href="https://www.linkedin.com/in/zhangshengdong/" class="iconfont icon-linkedin" title="linkedin"></a>
      <a href="https://github.com/zhangsheng377/" class="iconfont icon-github" title="github"></a>
  <a href="https://www.zhangshengdong.com/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  <div class="busuanzi-footer">
    <span id="busuanzi_container_site_pv"> 本站总访问量 <span id="busuanzi_value_site_pv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> 次 </span>
      <span class="division">|</span>
    <span id="busuanzi_container_site_uv"> 本站总访客数 <span id="busuanzi_value_site_uv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> 人 </span>
  </div>

  <span class="copyright-year">
    &copy; 
    2019 - 
    2022<span class="heart"><i class="iconfont icon-heart"></i></span><span><a href="https://beian.miit.gov.cn/" target="_blank">苏ICP备15009593号-1</a></span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.c12618f9a600c40bd024996677e951e64d3487006775aeb22e200c990006c5c7.js"></script>
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        tags: 'ams',
        }
    };
  </script>
  <script async src="https://cdn.jsdelivr.net/npm/mathjax@3.0.5/es5/tex-mml-chtml.js" integrity="sha256-HGLuEfFcsUJGhvB8cQ8nr0gai9EucOOaIxFw7qxmd+w=" crossorigin="anonymous"></script>

<script id="baidu_analytics">
  var _hmt = _hmt || [];
  (function() {
    if (window.location.hostname === 'localhost') return;
    var hm = document.createElement("script"); hm.async = true;
    hm.src = "https://hm.baidu.com/hm.js?c602db2501643f661d9789f9e9707386";
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(hm, s);
  })();
</script>






</body>
</html>
